{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import getpass\n",
    "import re\n",
    "import unidecode\n",
    "import csv\n",
    "import os\n",
    "import random\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The function implementing the original idea to work with the whole Drama Corpus data**: network data for each play mined via the API, recorded into separate file for each sub-corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_network_metrics():\n",
    "    url_base = 'http://dracor.org/api/corpora/'\n",
    "\n",
    "    r = requests.get(url_base)\n",
    "    corpora = [item for item in r.json()]\n",
    "    \n",
    "    with open('canon.csv', 'w', newline='') as canoncsv:\n",
    "        fieldnames = ['name', 'size', 'diameter',\n",
    "                      'density', 'averageClustering',\n",
    "                      'averagePathLength', 'maxDegree']\n",
    "        canonwriter = csv.DictWriter(canoncsv, fieldnames=fieldnames, delimiter=';')\n",
    "        canonwriter.writeheader()\n",
    "\n",
    "    for corpus in corpora:\n",
    "        print(corpus['name'])\n",
    "        fname = corpus['name'] + '.csv'\n",
    "    \n",
    "        r = requests.get(url_base + corpus['name'])\n",
    "        dramas = [drama['name'] for drama in r.json()['dramas']]\n",
    "        \n",
    "        if not os.path.exists(fname):\n",
    "            with open(fname, 'w', newline='') as csvfile:\n",
    "                fieldnames = ['name', 'size', 'diameter', \n",
    "                              'density', 'averageClustering', \n",
    "                              'averagePathLength', 'maxDegree']\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames, delimiter=';')\n",
    "                writer.writeheader()\n",
    "\n",
    "                for drama in dramas:\n",
    "                    print(drama)\n",
    "                    r = requests.get(url_base + corpus['name'] + \n",
    "                                     '/play/' + drama + '/metrics')\n",
    "\n",
    "                    metrics = r.json()          \n",
    "                    writer.writerow({fieldname: metrics[fieldname] for fieldname in fieldnames})\n",
    "\n",
    "get_network_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading the network data for the subset of drama corpus constituting the minimal canon of European drama as assembled by F.Fischer et al. for the poster contribution to DH2018 via the repository at https://github.com/lehkost/dramenquartett"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "username = 'wildlighted'\n",
    "password = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_canon_plays(): \n",
    "    \n",
    "    r = requests.get('https://raw.githubusercontent.com/lehkost/dramenquartett/' \\\n",
    "                     'master/dh2018-mexico/brecht_beats_shakespeare_data.csv')\n",
    "    raw_text = r.text\n",
    "    text = unidecode.unidecode(raw_text.lower())\n",
    "    plays = text.split('\\n')[1:-1]\n",
    "    return plays\n",
    "         \n",
    "plays = get_canon_plays()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data unified, cleaned and assembled into a dataset of different format for further work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_canon():\n",
    "    \n",
    "    with open ('canon.csv', 'w', encoding='utf-8') as f:\n",
    "        fieldnames = ['id', 'name', 'size', 'diameter',\n",
    "                          'density', 'averageClustering',\n",
    "                          'averagePathLength', 'maxDegree']\n",
    "        f.write((';'.join(fieldnames)+'\\n'))\n",
    "        \n",
    "        id = 1\n",
    "        for line in plays:\n",
    "            fields = re.split(',(?!\\d+\"|\\s\\w+)', line)\n",
    "            author = fields[0].split()[-1]\n",
    "            title = '-'.join(re.sub('[^\\w\\d\\s]+', '', fields[1]).split())\n",
    "            name = author + '-' + title\n",
    "            metrics = [field.strip('\"') for field in fields[5:-1]]\n",
    "            metrics = [re.sub(',', '.', metric) for metric in metrics]\n",
    "            f.write(str(id) + ';' + name + ';' + ';'.join(metrics) + '\\n')\n",
    "            id += 1\n",
    "\n",
    "if not os.path.exists('canon.csv'):\n",
    "    write_canon()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average value for each of the six metrics calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'size': 37.21875, 'diameter': 3.125, 'density': 0.41625000000000006, 'averageClustering': 0.8390624999999998, 'averagePathLength': 1.7487500000000007, 'maxDegree': 25.53125}\n"
     ]
    }
   ],
   "source": [
    "def count_average(filename):\n",
    "    \n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        plays = f.readlines()[1:]\n",
    "    avgmetrics = {'size': 0, 'diameter': 0, 'density': 0, \n",
    "                  'averageClustering': 0, 'averagePathLength': 0, 'maxDegree': 0}\n",
    "    for play in plays:\n",
    "        metrics = play.split(';')[2:]\n",
    "        for i, metric in enumerate(metrics):\n",
    "            avgmetrics[list(avgmetrics.keys())[i]] += float(metric)\n",
    "    avgmetrics = {key: avgmetrics[key]/len(plays) for key in list(avgmetrics.keys())}\n",
    "    \n",
    "    return avgmetrics\n",
    "\n",
    "averages = count_average('canon.csv')\n",
    "#print(averages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function calculating the divergence of all the metrics of a play from the average. Average path length taken with the opposite sign, as its lower value trumps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_divergence(metrics, avgs):\n",
    "    \n",
    "    divs = {}\n",
    "    for i, metric in enumerate(metrics):\n",
    "        divs[list(avgs.keys())[i]] = metric - avgs[list(avgs.keys())[i]]\n",
    "    divs['averagePathLength'] = -divs['averagePathLength']\n",
    "    \n",
    "    return divs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function forming two random decks from a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def form_deck(csvfile, size):\n",
    "    \n",
    "    with open(csvfile, 'r') as f:\n",
    "        cards = f.readlines()[1:]\n",
    "        random.shuffle(cards)\n",
    "        print(len(cards))\n",
    "        first_deck, second_deck = deque(cards[:size//2]), deque(cards[size//2:])\n",
    "        \n",
    "    return first_deck, second_deck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function simulating one turn of a game.\n",
    "Depending on the variable indicating which player is choosing, the metric with the highest divergence from average from the corresponding card is chosen, compared with the same metric on the other card. Cards from the table are added to the bottom of the winning player's deck.\n",
    "In case of a draw, recursion is used until the draw is resolved.  \n",
    "All the specifics of the turn including cards, choosing player, winner, metric are logged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metricnames = ['size', 'diameter', 'density',\n",
    "               'averageClustering', 'averagePathLength', 'maxDegree']\n",
    "\n",
    "def one_turn(first_deck, second_deck):\n",
    "    card_1 = first_deck.pop()\n",
    "    card_2 = second_deck.pop()\n",
    "    global table\n",
    "    table.extend([card_1, card_2])\n",
    "    print(table)\n",
    "    \n",
    "    log = card_1[:-1] + ',' + card_2[:-1] + ','\n",
    "    \n",
    "    metrics_card_1, metrics_card_2 =  [float(metric) for metric in card_1.split(';')[2:]], \\\n",
    "                            [float(metric) for metric in card_2.split(';')[2:]]\n",
    "    metrics_1, metrics_2 = {}, {}\n",
    "    \n",
    "    for i, metric1 in enumerate(metrics_card_1):\n",
    "        metrics_1[metricnames[i]] = metric1\n",
    "    for j, metric2 in enumerate(metrics_card_2):\n",
    "        metrics_2[metricnames[j]] = metric2\n",
    "    \n",
    "    divs_1, divs_2 = count_divergence(metrics_card_1, averages), \\\n",
    "                        count_divergence(metrics_card_2, averages)\n",
    "    \n",
    "    global first_player\n",
    "    if first_player:\n",
    "        log += '1,'\n",
    "        inv_divs = {value: key for key, value in divs_1.items()}\n",
    "        number = max(divs_1.values())\n",
    "    else:\n",
    "        log += '2,'\n",
    "        inv_divs = {value: key for key, value in divs_2.items()}\n",
    "        number = max(divs_2.values())\n",
    "        \n",
    "    value_1 = {inv_divs[number]: metrics_1[inv_divs[number]]}\n",
    "    value_2 = {inv_divs[number]: metrics_2[inv_divs[number]]}\n",
    "    metricname = list(value_1.keys())[0]\n",
    "    \n",
    "    log += metricname + ',' + str(metrics_1[inv_divs[number]]) + ',' \\\n",
    "    + str(metrics_2[inv_divs[number]]) + ',' + \\\n",
    "    str(divs_1[inv_divs[number]]) + ',' + str(divs_2[inv_divs[number]]) + ','\n",
    "    \n",
    "\n",
    "    if metricname != 'averagePathLength':\n",
    "        if value_1[metricname] > value_2[metricname]:\n",
    "            first_deck.extendleft(table)\n",
    "            first_player = True\n",
    "            log += '1'\n",
    "        elif value_1[metricname] == value_2[metricname]:\n",
    "            if first_deck and second_deck:\n",
    "                one_turn(first_deck, second_deck)\n",
    "                log += '0'\n",
    "            elif first_player:\n",
    "                first_deck.extendleft(table)\n",
    "                log += '1'\n",
    "            else:\n",
    "                second_deck.extendleft(table)\n",
    "                log += '2'\n",
    "        else:\n",
    "            second_deck.extendleft(table)\n",
    "            first_player = False\n",
    "            log += '2'\n",
    "    else:\n",
    "        if value_1[metricname] < value_2[metricname]:\n",
    "            first_deck.extendleft(table)\n",
    "            first_player = True\n",
    "            log += '1'\n",
    "        elif value_1[metricname] == value_2[metricname]:\n",
    "            if first_deck and second_deck:\n",
    "                one_turn(first_deck, second_deck)\n",
    "                log += '0'\n",
    "            elif first_player:\n",
    "                first_deck.extendleft(table)\n",
    "                log += '1'\n",
    "            else:\n",
    "                second_deck.extendleft(table)\n",
    "                log += '2'\n",
    "        else:\n",
    "            second_deck.extendleft(table)\n",
    "            first_player = False\n",
    "            log += '2'\n",
    "    table.clear()\n",
    "    return log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function simulating one game.\n",
    "One turn function is repeated until one of the decks is left empty.\n",
    "Each game process is logged into a separate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_game(game_number):\n",
    "    \n",
    "    deck_1, deck_2 = form_deck('canon.csv', 32)\n",
    "\n",
    "    with open ('game_' + str(game_number) + '_deck_1.csv', 'w', encoding='utf-8') as f:\n",
    "        for card in deck_1:\n",
    "            f.write(card)\n",
    "    with open ('game_' + str(game_number) + '_deck_2.csv', 'w', encoding='utf-8') as f:\n",
    "        for card in deck_2:\n",
    "            f.write(card)\n",
    "\n",
    "    global table\n",
    "    table = []\n",
    "    j = 1    \n",
    "    global first_player\n",
    "    first_player = True\n",
    "    with open('game_' + str(game_number) + '.csv', 'w', encoding='utf-8') as f:\n",
    "        f.write('turn,card1,card2,chooser,metric,value1,value2,div1,div2,winner\\n')\n",
    "        while deck_1 and deck_2:\n",
    "            turn_log = str(j) + ',' + one_turn(deck_1, deck_2) + '\\n'\n",
    "            f.write(turn_log)\n",
    "            #print(j, len(deck_1), len(deck_2))\n",
    "            j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nececcary number of games is simulated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 101):\n",
    "    one_game(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
